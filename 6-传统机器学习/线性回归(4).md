基本概念：

线性回归（Linear regression）是利用称为线性回归方程的最小二乘函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。

线性回归的应用范围很广，可以应用在包括金融，趋势线，经济学，传染病学等一系列常见领域，是一种很常见的也是最为简单的一种模型。大多情况下的应用均为预测或者映射，线性回归可以用来对观测数据集的和X的值拟合出一个预测模型。当完成这样一个模型以后，对于一个新增的X值，在没有给定与它相配对的y的情况下，可以用这个拟合过的模型预测出一个y值。接下来本章的讨论也均为建立在这种问题之上。

## 1.1一元线性回归
### 1.1.1函数模型
一元线性回归线性回归，又称简单线性回归（simple linear regression, SLR），是最简单但用途很广的回归模型。

其函数模型为：
Y=AX+B
我们用一元线性模型来拟合目前所拥有的数据，来预测未知的数据。所谓拟合就是用一个函数模型去逼近实际的数据分布。这里涉及到怎样确定函数模型才能使拟合程度更高（预测值与实际值偏差最小）的问题，我们一般使用的是最小二乘法。

![image](https://note.youdao.com/yws/public/resource/f3907b75ffed04a0aae0a4ccbc564979/xmlnote/EF7B9A037DF44CDD91092B31A0C89DD8/12)
图一

![image](https://note.youdao.com/yws/public/resource/f3907b75ffed04a0aae0a4ccbc564979/xmlnote/45B9570E9F6D4F6690C1157794C32001/13)
图二

如图所示，假设为房屋面积与售价的关系，我们针对这种图一所示分布的数据，可以采用一条直线来拟合模型的整体走势。具体解法见下一节最小二乘法内容。

### 1.1.2最小二乘法
确定我们使用一元线性模型来解决这个问题。建立一个模型之后，想知道的第一个问题就是。这个模型的准确度怎么样。那衡量的标准是什么呢，就是保证所有数据偏差的平方和最小。这就引入了我们本届要讲的最小二乘法。最小二乘法使在线性回归下采用最小二乘准则（或者说叫做最小平方），进行线性拟合参数求解的、矩阵形式的公式方法。这种方法求得是全局最优解。
给出一组{Xi，Yi}的数据，我们首先可以绘制出有关数据的散点图
（使用数据集 http://archive.ics.uci.edu/ml/datasets/Housing 只取部分面积房价数据）

Python代码如下：

```
# -*- coding: utf-8 -*
import numpy as np
import os
import matplotlib.pyplot as plt
def drawDiagram(fileName):
    #改变工作路径到数据文件存放的地方
    os.chdir("d:/data")
    xcord=[];ycord=[]
    fr=open(fileName)
    for line in fr.readlines():
        lineArr=line.strip().split()
        xcord.append(float(lineArr[1]));ycord.append(float(lineArr[2]))
    plt.scatter(xcord,ycord,s=30,c='red',marker='s')
    plt.show()

```
我们任取两点建立一个模型Y=Ax+B，那接下来就进入最开始的问题了，我们要看这个A，B对应的模型是不是最优模型，即是不是能让所有数据偏差的平方和最小。
即![image](https://note.youdao.com/yws/public/resource/f3907b75ffed04a0aae0a4ccbc564979/xmlnote/4EA3A58577A44F2E98112F0340A240AE/27)我们现在要求使M最小的a，b的值。方程为a，b为自变量，M为因变量的函数，可对M求关于a，b偏导求得。
求解下面方程组可以求得
![image](https://note.youdao.com/yws/public/resource/f3907b75ffed04a0aae0a4ccbc564979/xmlnote/167C0182AEB546F98668C9EEB77E27B4/26)

![image](https://note.youdao.com/yws/public/resource/f3907b75ffed04a0aae0a4ccbc564979/xmlnote/46682085886D47F487CB06E7F0A90CCB/28)

Python实现代码如下：

```
# -*- coding: utf-8 -*
import numpy as np
import os
import matplotlib.pyplot as plt
def drawDiagram(fileName):
    #改变工作路径到数据文件存放的地方
    os.chdir("d:/workspace_ml")
    xcord=[];ycord=[]
    fr=open(fileName)
    for line in fr.readlines():
        lineArr=line.strip().split()
        xcord.append(float(lineArr[1]));ycord.append(float(lineArr[2]))
    plt.scatter(xcord,ycord,s=30,c='red',marker='s')
    #a=0.1965;b=-14.486
    a=0.1612;b=-8.6394
    x=np.arange(90.0,250.0,0.1)
    y=a*x+b
    plt.plot(x,y)
    plt.show()

```
## 1.2多元线性回归
讲完一元线性回归后，我们把范围稍微拓展一下，由单个自变量变为多个自变量，这称之为多元线性回归。还是以房价预测为例子，上一节我们只取了面积与房价的关系，实际来说情况要复杂得多，可能还会与房间数，卧室数目等一系列别的问题相关。
设p个自变量（X1,X2…Xp）m个因变量，有总体回归模型如下
![image](https://note.youdao.com/yws/public/resource/f3907b75ffed04a0aae0a4ccbc564979/xmlnote/F027AC01E70E4092AB56EB47012C6219/47)
![image](https://note.youdao.com/yws/public/resource/f3907b75ffed04a0aae0a4ccbc564979/xmlnote/21ED211D03DD466FB202B944AD587C38/46)

......

![image](https://note.youdao.com/yws/public/resource/f3907b75ffed04a0aae0a4ccbc564979/xmlnote/4B4B9E83322949CDAC9B80F6EED88B54/45)

也就是假设每个指标Yi与自变量Xj之间存在线性关系。直观来说，还是以之前的房价数据集为例子，我们可以认为房间数，卧室数等不同的因素占的权重不同。100平的一居室价格可能低于100平的二居室。误差项e=[e1,e2,…,em]’满足假设
Ee=0,Cov(e)=∑▒=(σij)
上面的模型可以划为相应的矩阵形式：

![image](https://note.youdao.com/yws/public/resource/f3907b75ffed04a0aae0a4ccbc564979/xmlnote/F9EB4AFB9B254942986EA7504DDC9BC0/43)

![image](https://note.youdao.com/yws/public/resource/f3907b75ffed04a0aae0a4ccbc564979/xmlnote/DA2E02963024400EB539F4EF13F56848/44)

对任意i，Xi0=1

参数矩阵与随机测量误差为

![image](https://note.youdao.com/yws/public/resource/f3907b75ffed04a0aae0a4ccbc564979/xmlnote/096798648BE64914B37CDC5FB17BA09C/42)

![image](https://note.youdao.com/yws/public/resource/f3907b75ffed04a0aae0a4ccbc564979/xmlnote/31761AE058084572803BC2F04EE65365/41)

多元线性回归模型的表述为

![image](https://note.youdao.com/yws/public/resource/f3907b75ffed04a0aae0a4ccbc564979/xmlnote/DF713E69787B4A08B260FB0B9DC160D1/48)

针对这种多元线性回归，明显已经很难一步步实现整个算法模型，我们推荐使用从sklearn等框架中直接调用线性回归模型。数据集依然使用经典的波士顿房价预测问题。
Python代码如下：

```
import matplotlib.pylab as plt
import numpy as np
from sklearn import linear_model

datasets_x = []
datasets_y = []

fr = open('prices.txt', 'r')

lines = fr.readlines()

for line in lines:
    items = line.strip().split(',')
    datasets_x.append(int(items[0]))
    datasets_y.append(int(items[1]))

print(datasets_x,'---------------------------------', datasets_y)

length = len(datasets_x)
datasets_x = np.array(datasets_x).reshape([length, 1])
datasets_y = np.array(datasets_y)

print(datasets_x)
print(datasets_y)

minX = min(datasets_x)
maxX = max(datasets_x)

print(minX)
print(maxX)

x = np.arange(minX, maxX)

print(x)

x = np.arange(minX, maxX).reshape([-1, 1])
print(x)

linear = linear_model.LinearRegression()
linear.fit(datasets_x, datasets_y)

#
plt.scatter(datasets_x, datasets_y, color = 'red')

plt.plot(x, linear.predict(x), color = 'blue')
plt.xlabel('Area')
plt.ylabel('Price')

```
## 1.3广义线性回归
在这之前我们已经将由单一自变量拓宽到了矩阵，接下来我们进一步拓宽应用范围，将范围拓宽到G（y）=Ax+b。即将y变为关于y的函数，G（y）可以为任意曲线方程。通过非线性关联函数，总体的均值因线性预测变量而异。响应概率分布可以是指数分布系列中的任意一种。

这给我们之后的处理带了很大的空间。在这里仅做简单介绍。

