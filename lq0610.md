# 正则化

---

对于算法而言，算法的效果不仅仅受假设空间函数数量的影响，也取决于这些函数的形式。可以给代价函数添加**正则化项**的惩罚，来表达对不同解的偏好，目的在于减少泛化误差。
正则化通过对目标函数*J*添加一个参数范数惩罚Ω(θ)，来限制模型的学习能力，可以将正则化之后的目标函数记为

*J̃(θ; X, y) = J (θ; X, y) + αΩ(θ),*

其中α是权衡范数惩罚项和标准目标函数相对贡献的超参数。若α为0，则没有正则化。α越大时，所对应的正则化惩罚越大。

---

#模型评价方法介绍
为了对模型的效果进行评估，需要好的评估方法，还需要衡量模型泛化能力的评价标准。常用的性能评价有：
###准确率和错误率
这是分类任务常见的评价标准，定义如下：准确率为分类任务中分类正确的样本数在总样本数中所占比例，错误率为分类错误的样本数在总样本中所占比例。
###精度，召回和F1
准确率和错误率虽然常见，但是不一定能很好的满足需求。**精度（presicion）**和**召回（recall）**又可以称为查准率和查全率。对于一个二分类问题，可以将训练集的真实类别与模型预测得到的类别组合，得到以下四种类型：TP（True Positive），TN（True Nagetive），FP（False Positive），FN（False Nagetive）。所有的训练集中的样例都可以被分为这四种类型，组成一个混淆矩阵。
精度和召回可以分别这样定义：
P = TP/（TP+FP）
R = TP/（TP+FN）
精度和召回往往是一对矛盾的变量。如果按照预测为正例的概率大小进行排序，按照顺序依次进行预测，得到精度和召回，可以绘制一条P-R曲线。P-R图可以直观地展示样本整体的精度和召回的情况。
为了综合考虑精度和召回，也常常用F1度量。F1基于精度和召回的调和平均来定义，其计算方法为：
F1 = 2 * P *R / (P + R)
###roc 和 auc
ROC与P-R曲线类似，按照预测结果对样例进行排序，按照顺序依次进行预测，计算TPR和FPR，可以绘制一条ROC曲线。
对模型进行评价时，若某ROC曲线可以将另一条ROC曲线完全包裹，则可以说明效果要好于被包裹的ROC曲线，否则，若两条ROC曲线存在交叉，则很难评价哪一条曲线更优。
AUC（area under curve）即ROC曲线下的面积。（随机给定一个正样本和一个负样本，分类器输出该正样本为正的那个概率值 比 分类器输出该负样本为正的那个概率值 要大的可能性）

