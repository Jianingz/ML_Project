
# 简单数据预处理

本书中我们主要处理的数据分为记录和图片。

# 记录数据

| 序号   | 姓名   | 成绩   | 年龄   | 身高  |
| :----: | :----: | :----: | :----: | :---: |
| 1      | 张三   | B      | 20     | 175   |
| 2      | 李四   | C      | 21     | 180   |
| 3      | 李磊   | A      | 25     | 172   |
| 4      | 韩梅   | A      | 24     | 163   |

在表格数据中，每一列称作数据的一个 *特征*(feature)，或者 *属性*(Attribute)。每一行称作一条 *记录*(record),或者 *实例*(instance)，或者 *对象*(object)。

每个特征的值可以是数值或者符号。
## 1.1.1 特征类型度量
当我们拿到一个数据集，在做预处理的时候我们需要把数据分成不同的类别，防止对一些特定的数据做违法的操作。比如对于年份数据，我们不能做加法和乘除法操作，因为这些操作没有意义。
在统计学中，一般情况下我们把数据特征分为4类，**Nominal**、**Ordinal**、**Interval**、**Ratio**，下面将分别说明。

**Nominal**:定义数据，也可称为名义数据，一般指标签或者代号，定义数据是不可计量的。定义数据只提供了可以区别两个记录的信息。如姓名，名称，方位，都是定义数据。

**Ordinal**:定序数据，是有顺序的数据。定序数据提供了可以对记录进行排序的信息。如成绩由好到坏可以分为A、B、C、D。

**Interval**:定距数据，数据没有真正的0点。两个记录特征值的差值是有意义的。如华氏温度，摄氏温度，年龄。

**Ration**:定比数据，有真正0点。两个记录特征值的比率是有意义。比如质量，高度。如身高，体重，开氏温度。

下表说明了不同类型的特征可以进行的操作。

| 操作   | 定义数据 | 定序数据 | 定距数据 | 定比数据 |
| :----: | :----:   | :----:   | :----:   | :----:   |
| 特异性 | √        | √        | √        | √        |
| 排序   | ×        | √        | √        | √        |
| 加减   | ×        | ×        | √        | √        |
| 乘除   | ×        | ×        | ×        | √        |
| 众数   | √        | √        | √        | √        |
| 中位数 | ×        | √        | √        | √        |
| 平均数 | ×        | ×        | √        | √        |
| 方差   | ×        | ×        | √        | √        |

## 1.1.2 图片数据
图片数据

# 1.2 数据清洗
我们现实中收集的原始数据想要不经过处理直接进行训练是不现实的。对于原始数据，我们需要经过预处理的步骤将数据加工为可以进行训练的数据集。首先我们关注的是数据质量问题，在这个方面，我们要检查数据是否有噪声和离群点，每条记录中是否有缺失的特征值，是否有两条记录是重复的等等。
对于噪声和离群点，一般情况下我们会直接移除这条记录。
对于丢失数据，我们首先会想通过其他的数据比如平均值和众数来补充，如果判断该条记录重要性不高，也可以移除。
对于重复数据，一般情况下只保留一个数据并删除其他数据。

*噪声*表明数据在原始值的基础上有随机的变化，一般来源于测量误差。为了降低噪声对模型训练的影响，我们首先可以寻找一些低噪声的数据。其次，可以采用一些降噪方法来降低噪声的干扰。
*离群点*是指某一条记录的特征和其他所有记录都有较大差异，在散点图上表现为离群点和其他大多数记录点的距离都很远。对于离群点，我们首先观察是否有单位错误导致的数量级误差，有的话可以统一单位。对于其他原因都可以删除离群点。
*丢失数据*是指一条记录中的某一条或者某几条特征值缺失。丢失数据主要有两个原因，第一是信息在收录的过程中没有被采集到，例如有些人不愿意在调查表中填写身高和体重的数据。第二是特征可能不适用于该条记录，例如一个调查表中成人可以填写收入，而儿童则没有。
处理丢失数据的方法
- 删除有丢失数据的数据记录(删除行)
- 删除有丢失数据的数据特征(删除列，在这个特征有大量数据缺失的时候)
- 忽略丢失数据
- 尝试填充丢失数据(以平均值，加权平均值等替代)
*重复数据*重复数据包括记录重复或者记录特征重复。记录重复指同一数据集中有两个记录个特征都一样。记录特征重复指在一个数据集中同一个人有两个不同的邮箱，数据集将其视为两个人。重复数据一般是在合并来源不同的数据集的时候产生的。对于重复数据一般取其中一个即可。

# 1.3 数据标准化
在一些机器学习算法中，特征的规模对学习的影响很大，数量级大的特征往往在学习中占据主导地位。而原始数据的量级和量纲通常是不一样的，这会对我们的机器学习算法造成很大的困扰，甚至完全无法正常工作。因此将数据标准化到一个特定的小区间在数据预处理缓解是非常有必要的一件事情。此外，更小的特征值范围也有利于模型迅速收敛。
在机器学习中，数据标准化通常有4种方法。
- 比例调节
>$$
x=\frac{x-{\text{min}}(x)}{{\text{max}}(x)-{\text{min}}(x)}
$$
- Z-score 标准化
>$$
x'=\frac{x-{\text{mean}}(x)}{{\text{max}}(x)-{\text{min}}(x)}
$$
- 单位长度缩放
>$$
x'{\frac {x}{||x||}}
$$
这里只需要大概了解，有个印象，我们将在实战环节一一介绍每种标准化的实现方法和用途。

# 1.4 独热编码(one-hot encoding)
在机器学习中，我们经常要对类别特征进行处理，这类特征一般而言是离散数据，转换为数值后会被模型认为是连续数据从而对训练有很大的负面作用。例如我们将年级{大一，大二，大三，大四}分别给与{0,1,2,3}的编码，模型就会认为大四的数值比大一大，它的权重就会高，而实际上这他们是完全相等的。为了避免这个问题，我们引入了独热编码。独热编码在数字电路中给与每一个状态一个寄存器，寄存器可以表达0或者1，在同一时间所有表达状态的寄存器只有一个置1，其余全为0。在机器学习中，对于N个类别，我们用N个比特位来表示所有状态。下表将简单的演示独热编码。

|年级|数字编码|独热编码|
|:-:|:-:|:-:|
|大一|0|1000|
|大二|1|0100|
|大三|2|0010|
|大四|3|0001|

# 1.5 实战演练

python中有很多包都可以进行数据清洗的操作，比较基本的方法是使用pandas包进行，这也是我们将主要使用的包。
- pandas 简介
pandas是一个开源的python包，它提供了高效，易用，灵活的数据结构和数据分析方式。pandas本身支持读写多种形式的文件:CSV and text files, Microsoft Excel, SQL databases, and the fast HDF5 format。其内置函数较为完整的包含了数据分析的方方面面，包括数据清洗。

下面我们用一个分析美国2011-2016年H1b签证的例子来说明数据清洗的一般步骤

``` javascript
import pandas as pd #习惯性的将pandas缩写为pd
data_h1b=read_csv('h1b_kaggle.csv') #读取.csv文件
data_h1b.head() #显示前几行作为数据预览
```
