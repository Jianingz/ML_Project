{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_h1b=pd.read_csv('h1b_kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CASE_STATUS</th>\n",
       "      <th>EMPLOYER_NAME</th>\n",
       "      <th>SOC_NAME</th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>FULL_TIME_POSITION</th>\n",
       "      <th>PREVAILING_WAGE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>WORKSITE</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CERTIFIED-WITHDRAWN</td>\n",
       "      <td>UNIVERSITY OF MICHIGAN</td>\n",
       "      <td>BIOCHEMISTS AND BIOPHYSICISTS</td>\n",
       "      <td>POSTDOCTORAL RESEARCH FELLOW</td>\n",
       "      <td>N</td>\n",
       "      <td>36067.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>ANN ARBOR, MICHIGAN</td>\n",
       "      <td>-83.743038</td>\n",
       "      <td>42.280826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CERTIFIED-WITHDRAWN</td>\n",
       "      <td>GOODMAN NETWORKS, INC.</td>\n",
       "      <td>CHIEF EXECUTIVES</td>\n",
       "      <td>CHIEF OPERATING OFFICER</td>\n",
       "      <td>Y</td>\n",
       "      <td>242674.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>PLANO, TEXAS</td>\n",
       "      <td>-96.698886</td>\n",
       "      <td>33.019843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CERTIFIED-WITHDRAWN</td>\n",
       "      <td>PORTS AMERICA GROUP, INC.</td>\n",
       "      <td>CHIEF EXECUTIVES</td>\n",
       "      <td>CHIEF PROCESS OFFICER</td>\n",
       "      <td>Y</td>\n",
       "      <td>193066.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>JERSEY CITY, NEW JERSEY</td>\n",
       "      <td>-74.077642</td>\n",
       "      <td>40.728158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CERTIFIED-WITHDRAWN</td>\n",
       "      <td>GATES CORPORATION, A WHOLLY-OWNED SUBSIDIARY O...</td>\n",
       "      <td>CHIEF EXECUTIVES</td>\n",
       "      <td>REGIONAL PRESIDEN, AMERICAS</td>\n",
       "      <td>Y</td>\n",
       "      <td>220314.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>DENVER, COLORADO</td>\n",
       "      <td>-104.990251</td>\n",
       "      <td>39.739236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>WITHDRAWN</td>\n",
       "      <td>PEABODY INVESTMENTS CORP.</td>\n",
       "      <td>CHIEF EXECUTIVES</td>\n",
       "      <td>PRESIDENT MONGOLIA AND INDIA</td>\n",
       "      <td>Y</td>\n",
       "      <td>157518.4</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>ST. LOUIS, MISSOURI</td>\n",
       "      <td>-90.199404</td>\n",
       "      <td>38.627003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          CASE_STATUS  \\\n",
       "0           1  CERTIFIED-WITHDRAWN   \n",
       "1           2  CERTIFIED-WITHDRAWN   \n",
       "2           3  CERTIFIED-WITHDRAWN   \n",
       "3           4  CERTIFIED-WITHDRAWN   \n",
       "4           5            WITHDRAWN   \n",
       "\n",
       "                                       EMPLOYER_NAME  \\\n",
       "0                             UNIVERSITY OF MICHIGAN   \n",
       "1                             GOODMAN NETWORKS, INC.   \n",
       "2                          PORTS AMERICA GROUP, INC.   \n",
       "3  GATES CORPORATION, A WHOLLY-OWNED SUBSIDIARY O...   \n",
       "4                          PEABODY INVESTMENTS CORP.   \n",
       "\n",
       "                        SOC_NAME                     JOB_TITLE  \\\n",
       "0  BIOCHEMISTS AND BIOPHYSICISTS  POSTDOCTORAL RESEARCH FELLOW   \n",
       "1               CHIEF EXECUTIVES       CHIEF OPERATING OFFICER   \n",
       "2               CHIEF EXECUTIVES         CHIEF PROCESS OFFICER   \n",
       "3               CHIEF EXECUTIVES   REGIONAL PRESIDEN, AMERICAS   \n",
       "4               CHIEF EXECUTIVES  PRESIDENT MONGOLIA AND INDIA   \n",
       "\n",
       "  FULL_TIME_POSITION  PREVAILING_WAGE    YEAR                 WORKSITE  \\\n",
       "0                  N          36067.0  2016.0      ANN ARBOR, MICHIGAN   \n",
       "1                  Y         242674.0  2016.0             PLANO, TEXAS   \n",
       "2                  Y         193066.0  2016.0  JERSEY CITY, NEW JERSEY   \n",
       "3                  Y         220314.0  2016.0         DENVER, COLORADO   \n",
       "4                  Y         157518.4  2016.0      ST. LOUIS, MISSOURI   \n",
       "\n",
       "          lon        lat  \n",
       "0  -83.743038  42.280826  \n",
       "1  -96.698886  33.019843  \n",
       "2  -74.077642  40.728158  \n",
       "3 -104.990251  39.739236  \n",
       "4  -90.199404  38.627003  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_h1b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_h1bs=data_h1b.sample(n=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=data_h1b.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            3002458\n",
       "CASE_STATUS           3002445\n",
       "EMPLOYER_NAME         3002399\n",
       "SOC_NAME              2984724\n",
       "JOB_TITLE             3002415\n",
       "FULL_TIME_POSITION    3002443\n",
       "PREVAILING_WAGE       3002373\n",
       "YEAR                  3002445\n",
       "WORKSITE              3002458\n",
       "lon                   2895216\n",
       "lat                   2895216\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_h1b.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 缺失数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=pd.DataFrame({'序号':[1,2,3,4],'姓名':['张三','李四','李磊','韩梅'],'成绩':['B','C','A','A'],'年龄':[20,21,25,None],'身高':[175,None,None,None]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用isnull()函数可以直观的看到每一项是否有缺失，不过如果数据量太大，我们很难找到哪些数据有缺失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>序号</th>\n",
       "      <th>姓名</th>\n",
       "      <th>成绩</th>\n",
       "      <th>年龄</th>\n",
       "      <th>身高</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      序号     姓名     成绩     年龄     身高\n",
       "0  False  False  False  False  False\n",
       "1  False  False  False  False   True\n",
       "2  False  False  False  False   True\n",
       "3  False  False  False   True   True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个假设的数据集中我们要怎么操作呢？首先我我们可以统计每个特征或者每条记录缺失数据的分布情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "序号    0\n",
      "姓名    0\n",
      "成绩    0\n",
      "年龄    1\n",
      "身高    3\n",
      "dtype: int64\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(frame.isnull().sum(axis=0)) #纵向统计有多少缺失数据\n",
    "print(frame.isnull().sum(axis=1)) #横向统计有多少缺失数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   序号  姓名 成绩    年龄     身高\n",
      "0   1  张三  B  20.0  175.0\n",
      "1   2  李四  C  21.0    NaN\n",
      "2   3  李磊  A  25.0    NaN\n",
      "3   4  韩梅  A   NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "frame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从获取的信息中可以看出，在年龄这个特征中有1个缺失数据，在身高特征有3个缺失数据。在第2，3条记录分别有一个缺失数据，第4条有两个缺失数据。我们可以简单的删除这些有缺失数据的项，操作及结果如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   序号  姓名 成绩    年龄     身高\n",
      "0   1  张三  B  20.0  175.0\n"
     ]
    }
   ],
   "source": [
    "frame_dropall=frame.dropna() #删除所有有缺失数据的记录\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到dropna函数把所有的含有缺失数据的记录都删除了。不过很可能经过缺失数据删除后的数据集规模太小而无法使用，在这种情况下我们可以通过对缺失数据填补和删除特征来保持数据集规模。\n",
    "\n",
    "首先是年龄特征，我们经过对表的简单分析，可以看出这是一个学生成绩的表，所以学生的年龄应该差不多，我们可以用平均值来填补。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2=frame.fillna({'年龄':frame['年龄'].mean()}) #填充年龄的平均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fillna函数中的值可以是字典，它可以对某一列或者某几列的缺失数据进行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>序号</th>\n",
       "      <th>姓名</th>\n",
       "      <th>成绩</th>\n",
       "      <th>年龄</th>\n",
       "      <th>身高</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>张三</td>\n",
       "      <td>B</td>\n",
       "      <td>20.0</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>李四</td>\n",
       "      <td>C</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>李磊</td>\n",
       "      <td>A</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>韩梅</td>\n",
       "      <td>A</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   序号  姓名 成绩    年龄     身高\n",
       "0   1  张三  B  20.0  175.0\n",
       "1   2  李四  C  21.0    NaN\n",
       "2   3  李磊  A  25.0    NaN\n",
       "3   4  韩梅  A  22.0    NaN"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们就把年龄的缺失数据填上了，那么对于身高呢？经过观察可以发现，身高的缺失数据非常多，占到所有数据的75%。我们当然可以按照平均值来填补数据，但是会造成身高这一项失去特征表达的作用，因为所有项目都一样，因此我们可以删除这一列。这样可以尽可能的保留数据集中的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>序号</th>\n",
       "      <th>姓名</th>\n",
       "      <th>成绩</th>\n",
       "      <th>年龄</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>张三</td>\n",
       "      <td>B</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>李四</td>\n",
       "      <td>C</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>李磊</td>\n",
       "      <td>A</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>韩梅</td>\n",
       "      <td>A</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   序号  姓名 成绩    年龄\n",
       "0   1  张三  B  20.0\n",
       "1   2  李四  C  21.0\n",
       "2   3  李磊  A  25.0\n",
       "3   4  韩梅  A  22.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2.dropna(axis=1)  #按照列删除缺失数据，这里参数axis表达删除的方向，0表示按行删除，1表示按列删除。删除的是有缺失数据的一整行或列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面列出之前使用的dropna和fillna的所有用法。\n",
    "\n",
    "DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "\n",
    "### dropna\n",
    "\n",
    "| 参数 | 用法|\n",
    "| :- | :- |\n",
    "|axis|控制移除缺失数据的行或者列。有两个参数{0 或者 'index',1 或者 'columns'}，如果输入是0或者'index'则移除缺失数据的行（记录），如果输入是1或者'columns'就移除有缺失数据的列。默认是0。|\n",
    "|how|决定空缺数据移除出数据集的方式。有两个参数{'any','all'},如果输入是'any'只要这一行（列）有缺失数据，就移除这一行（列）。如果输入是'all'则只有在这一行（列）数据全部缺失后才移除。\n",
    "|tresh|控制每行（列）留下的非缺失数据个数。输入一个int型整数。\n",
    "|subset|控制从哪一行（列）寻找缺失数据。输入一个列表。如果想删除有缺失数据的行，就读入特征名作为列表里的值。\n",
    "|inplace|控制操作是直接作用在数据集上还是副本上。有两个参数{True，False},如果输入是True则在原始数据集上直接操作，返回None。如果是False则在生成的副本上操作，返回操作完成的副本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面对之前没有提到的操作进行举例说明，方便理解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   序号  姓名 成绩    年龄     身高\n",
      "0   1  张三  B  20.0  175.0\n",
      "1   2  李四  C  21.0    NaN\n",
      "2   3  李磊  A  25.0    NaN\n"
     ]
    }
   ],
   "source": [
    "frame_thr=frame.dropna(thresh=4) #控制有效值超过4个的数据记录保留\n",
    "print(frame_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   序号  姓名 成绩    年龄     身高\n",
      "0   1  张三  B  20.0  175.0\n",
      "1   2  李四  C  21.0    NaN\n",
      "2   3  李磊  A  25.0    NaN\n"
     ]
    }
   ],
   "source": [
    "frame_sub=frame.dropna(subset=['年龄']) #加入subset参数表示只观察年龄特征的参数，而不管其他特征是否有缺失数据\n",
    "print(frame_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   序号  姓名 成绩    年龄     身高\n",
      "0   1  张三  B  20.0  175.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "frame_in=frame.dropna(inplace=True) #可以看到inplace为True时函数直接在原始数据集上进行了操作，返回值是None\n",
    "print(frame)\n",
    "print(frame_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fillna\n",
    "DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
    "\n",
    "|参数|用法|\n",
    "|:--:|:--:|\n",
    "|value|需要填补的数据。允许读入的数据类型有标量数据、字典、序列和数据集。字典，序列和数据集可以指定需要填充数据的标签|\n",
    "|method|可以控制填充的方式。有5个参数{'backfill','bfill','pad','ffill',None},默认为None。\n",
    "backfill/bfill:用下一个非缺失数据区填充该数据，pad/fill:用前一个非缺失数据去填充该数据。None表示用制定的数据填充该缺失数据。\n",
    "|axis|控制操作方向。有两个参数{0 或者 'index',1 或者 'columns'}，默认为0。输入0表示按照行操作，1表示按照列操作。\n",
    "|implace|控制操作是直接作用在数据集上还是副本上。有两个参数{True，False},如果输入是True则在原始数据集上直接操作，返回None。如果是False则在生成的副本上操作，返回操作完成的副本。\n",
    "|limit| 控制沿轴填充缺失数据的最大个数。输入一个int型整数，默认为None。\n",
    "|downcast| 控制是否进行类型转换。输入一个字典{'对象':'数据类型'}。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重复数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=pd.DataFrame({'序号':[1,2,3,4,1],'姓名':['张三','李四','李磊','韩梅','张三'],'成绩':['B','C','A','A','B'],'年龄':[20,21,25,None,20],'身高':[175,None,None,None,175]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在原始数据集的基础上，增加一列新的数据，来讲解如何使用pandas包来处理重复数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   序号  姓名 成绩    年龄     身高\n",
      "0   1  张三  B    20  175.0\n",
      "1   2  李四  C    21    NaN\n",
      "2   3  李磊  A    25    NaN\n",
      "3   4  韩梅  A  None    NaN\n",
      "4   1  张三  B    20  175.0\n"
     ]
    }
   ],
   "source": [
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(frame.duplicated()) #查看是否有重复记录，只有所有特征都一样时判断为相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   序号  姓名 成绩    年龄     身高\n",
      "0   1  张三  B  20.0  175.0\n",
      "1   2  李四  C  21.0    NaN\n",
      "2   3  李磊  A  25.0    NaN\n",
      "3   4  韩梅  A   NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "print(frame.drop_duplicates()) #删除重复记录，默认保存第一个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面给出duplicated()和drop_duplicateds()的全部参数定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duplicated()\n",
    "DataFrame.duplicated(subset=None, keep='first')\n",
    "\n",
    "|参数|用法|\n",
    "|:-:|:-:|\n",
    "|subset|控制选择特定的特征判断重复。读入一个或一个序列的特征标签名。\n",
    "|keep|判断重复的记录的位置。有三个参数{'first','last',False},默认为first。如果输入为'first'，则除了第一出现的记录以外的其他记录都标记为重复（True）。如果输入为'last'则除了最后一个出现的记录以外的其他记录都标记为重复（True）。如果输入为False，则所有重复记录都标记为True。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=['序号','姓名']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['序号', '姓名']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(frame.duplicated(subset=l)) #记录仅有序号和姓名重复的记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(frame.duplicated(keep='last'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop_duplicated()\n",
    "DataFrame.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "\n",
    "|参数|用法|\n",
    "|:-:|:-:|\n",
    "|subset| 控制选择特定的特征判断重复。读入一个或一个序列的特征标签名。\n",
    "|keep| 判断重复的记录的位置。有三个参数{'first','last',False},默认为first。如果输入为'first'，则删除除了第一出现的记录以外的其他记录。如果输入为'last'则删除除了最后一个出现的记录以外的其他记录。如果输入为False，则删除所有重复记录。\n",
    "|inplace|控制操作是直接作用在数据集上还是副本上。有两个参数{True，False},如果输入是True则在原始数据集上直接操作，返回None。如果是False则在生成的副本上操作，返回操作完成的副本。\n",
    "\n",
    "操作与duplicated类似，所以不做详细举例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 离群值处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "离群值检测的方法有很多，下面介绍两种。\n",
    "\n",
    "1、3$\\sigma$\n",
    "- 如可以假设一元数据服从正态分布， $\\mu$为正态均值，$\\sigma$为正态标准差，则在($\\mu$-3$\\sigma$,$\\mu$+3$\\sigma$)的区间内包含99.97%的值。我们将距离均值超过3$\\sigma$的数据点都当做离群值处理。\n",
    "\n",
    "2、箱图\n",
    "- 我们还可以用一种叫做箱图的方法来检测离群值的方法。箱图是一种比较流行的观察离群值的方法，它可以直观的展示出数据的最大非离群点值，最小非离群点值，中位数，和第一、第三四分位数。其中第一四分位数可以用Q1表示,第三四分位数可以用Q3表示。中间四分位数极差用IQR表示，定义为Q3-Q1。最大非离群点值为小于Q3+1.5×IQR的最大值，最小非离群点为大于Q1-1.5×IQR的最小值。在(Q1-1.5×IQR,Q3+1.5×IQR)的区间内包含了99.3%的值，我们可以将区间之外的值当做是离群点。下图展示了一个简单的箱图说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们会使用一个简单的例子来说明如何观察箱图和如何在python中制作箱图，并用箱图来排除离群点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们可以生成100个随机数，再调用matplotlib 中绘制箱图的函数就可以轻松的绘制出简单的箱图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_data=np.random.randn(100) #生成100个随机数\n",
    "plt.boxplot(rand_data) #产生图片\n",
    "plt.show() #输出图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#生成100个随机数\n",
    "rand_data=np.random.randn(100) \n",
    "#产生图片\n",
    "plt.boxplot(rand_data) \n",
    "#输出图片\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们绘制出了箱图，从图中可以看出有两个离群值，所以我们需要对这两个离群值进行处理。对离群值我们可以把他们当做缺失值，根据具体情况用均值、最接近值等来填补。这里我们直接删除这条数据。下面是离群值筛选代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "离群值长度: 2\n",
      "有效值长度: 98\n",
      "随机数据长度: 100\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "rand_data=np.random.randn(100) #生成100个随机数\n",
    "#取第一四分位点Q1\n",
    "Q1 = np.percentile(rand_data, 25)\n",
    "#取第3四分位点Q3\n",
    "Q3 = np.percentile(rand_data, 75)\n",
    "#计算中间四分位数极差IQR\n",
    "IQR = Q3-Q1\n",
    "#使用布尔值索引，得到所有离群值数据\n",
    "data_OutLier = rand_data[(rand_data<Q1-1.5*IQR)|(rand_data>Q3+1.5*IQR)]\n",
    "#室友布尔值索引，得到所有有效值数据\n",
    "data_Processed =rand_data[(rand_data>Q1-1.5*IQR)&(rand_data<Q3+1.5*IQR)]\n",
    "\n",
    "#输出数据检测长度是否正确\n",
    "print('随机数据长度:',len(rand_data))\n",
    "print('离群值长度:',len(data_OutLier))\n",
    "print('有效值长度:',len(data_Processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 噪声处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们介绍对噪声进行分箱处理的方法。分箱在前面章节中介绍过2种分箱方法：等频，等宽。3种对箱内数据处理的方法：分别是取箱中位数、取箱中位数和按箱边界。下面的代码部分将分别展示各种分箱方法和箱内数据处理方法。代码实现比较基础，有改进空间，读者可以自行探索。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 等频分箱\n",
    "等频分箱是将数据按一定顺序排序后，每个箱中放入数量相等的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始随机数据: [ 3  4  1  9  5 10  8  3  8  0 13  5 12  1  3 10 11 12 13  9 13 13  2 11\n",
      "  2 14  6 13  8  9]\n",
      "排序数据: [ 0  1  1  2  2  3  3  3  4  5  5  6  8  8  8  9  9  9 10 10 11 11 12 12\n",
      " 13 13 13 13 13 14]\n",
      "箱1: [0 1 1 2 2 3]\n",
      "箱2: [3 3 4 5 5 6]\n",
      "箱3: [8 8 8 9 9 9]\n",
      "箱4: [10 10 11 11 12 12]\n",
      "箱5: [13 13 13 13 13 14]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(8)\n",
    "#首先生成30个随机整数\n",
    "rand_Noise=np.random.randint(15, size =30 ) \n",
    "print('原始随机数据:',rand_Noise)\n",
    "#对数据进行排序\n",
    "rand_NoiseSorted=np.sort(rand_Noise)\n",
    "print('排序数据:',rand_NoiseSorted)\n",
    "#假设分5个箱，可以用numpy自带的切片操作来进行等频分箱\n",
    "box_list=[]\n",
    "for i in range(5):\n",
    "    #data[x:y]的索引代表着在data在[x,y)的索引区间内的值\n",
    "    #如data[0,6]代表着data[0]到data[5]总共6个值\n",
    "    box_list.append(rand_NoiseSorted[6*i:6*i+6])\n",
    "#打印所有分箱情况\n",
    "for i in range(5):\n",
    "    print('箱%d:'%(i+1),box_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 等宽分箱\n",
    "等宽分箱是将变量的取值范围分成等宽的区间，每个区间视为一个分箱。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "箱1: [1, 0, 1, 2, 2]\n",
      "箱2: [3, 4, 5, 3, 5, 3]\n",
      "箱3: [8, 8, 6, 8]\n",
      "箱4: [9, 10, 10, 11, 9, 11, 9]\n",
      "箱5: [13, 12, 12, 13, 13, 13, 14, 13]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#设置分箱个数\n",
    "cut=5\n",
    "#使用pandas 的cut 功能进行分箱，cut数是所分箱的个数，返回一个pandas.categorical类型的指\n",
    "colBin = pd.cut(rand_Noise,cut)\n",
    "#初始化分箱，每个分箱由一个列表存储\n",
    "box_list=[]\n",
    "for i in range(cut):\n",
    "    box_list.append([])\n",
    "#按分好的categorical把数据放入箱中\n",
    "for i,j in zip(rand_Noise,colBin.codes):\n",
    "    box_list[j].append(i)\n",
    "#打印所有分箱情况\n",
    "for i in range (len(box_list)):\n",
    "    print ('箱%d:'%(i+1),box_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面介绍了等频和等宽的分箱方法，使用pandas和numpy库就可以十分轻松的实现。下面以等宽分箱的数据为例介绍如何光滑箱内数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 箱中位数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据：\n",
      "箱1: [0 1 1 2 2 3]\n",
      "箱2: [3 3 4 5 5 6]\n",
      "箱3: [8 8 8 9 9 9]\n",
      "箱4: [10 10 11 11 12 12]\n",
      "箱5: [13 13 13 13 13 14]\n",
      "光滑后数据\n",
      "箱1: [1.5, 1.5, 1.5, 1.5, 1.5, 1.5]\n",
      "箱2: [4.5, 4.5, 4.5, 4.5, 4.5, 4.5]\n",
      "箱3: [8.5, 8.5, 8.5, 8.5, 8.5, 8.5]\n",
      "箱4: [11.0, 11.0, 11.0, 11.0, 11.0, 11.0]\n",
      "箱5: [13.0, 13.0, 13.0, 13.0, 13.0, 13.0]\n"
     ]
    }
   ],
   "source": [
    "#数据展示\n",
    "print('原始数据：')\n",
    "for i in range (len(box_list)):\n",
    "    print ('箱%d:'%(i+1),box_list[i])\n",
    "#初始化箱\n",
    "box_MedianSmooth=[]\n",
    "#对每个箱进行遍历\n",
    "for i in range(len(box_list)):\n",
    "    #新建一个箱\n",
    "    box_MedianSmooth.append([])\n",
    "    #算出中位数\n",
    "    mid = np.median(box_list[i])\n",
    "    #将箱内每个数以中位数替换\n",
    "    for j in range(len(box_list[i])):\n",
    "        #使用浮点型防止有数组个数为偶数时可能造成的误差\n",
    "        box_MedianSmooth[i].append(mid)\n",
    "print('光滑后数据')\n",
    "for i in range (len(box_list)):\n",
    "    print ('箱%d:'%(i+1),box_MedianSmooth[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 箱平均数\n",
    "\n",
    "箱平均数与箱中位数同理，只需要将求中位数的函数换为求平均数的函数即可。numpy中求平均数的函数为numpy.mean()。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 箱边界\n",
    "\n",
    "箱边界需要对箱内数据和箱边界的距离进行判断，将数据光滑为更接近的那个边界，代码如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据：\n",
      "箱1: [0 1 1 2 2 3]\n",
      "箱2: [3 3 4 5 5 6]\n",
      "箱3: [8 8 8 9 9 9]\n",
      "箱4: [10 10 11 11 12 12]\n",
      "箱5: [13 13 13 13 13 14]\n",
      "光滑后数据\n",
      "箱1: [0, 0, 0, 3, 3, 3]\n",
      "箱2: [3, 3, 3, 6, 6, 6]\n",
      "箱3: [8, 8, 8, 9, 9, 9]\n",
      "箱4: [10, 10, 10, 10, 12, 12]\n",
      "箱5: [13, 13, 13, 13, 13, 14]\n"
     ]
    }
   ],
   "source": [
    "#数据展示\n",
    "print('原始数据：')\n",
    "for i in range (len(box_list)):\n",
    "    print ('箱%d:'%(i+1),box_list[i])\n",
    "#初始化箱\n",
    "box_EdgeSmooth=[]\n",
    "for i in range(len(box_list)):\n",
    "    #新建一个箱\n",
    "    box_EdgeSmooth.append([])\n",
    "    boxMax=np.max(box_list[i])\n",
    "    boxMin=np.min(box_list[i])\n",
    "    for j in range(len(box_list[i])):\n",
    "        if (box_list[i][j]-boxMin)>(boxMax-box_list[i][j]):\n",
    "            box_EdgeSmooth[i].append(boxMax)\n",
    "        else:\n",
    "            box_EdgeSmooth[i].append(boxMin)\n",
    "print('光滑后数据')\n",
    "for i in range (len(box_list)):\n",
    "    print ('箱%d:'%(i+1),box_EdgeSmooth[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这节内我们可以调用sklearn库来快速的进行标准化处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 比例调节\n",
    ">$$\n",
    "x'=\\frac{x-{\\text{min}}(x)}{{\\text{max}}(x)-{\\text{min}}(x)}\n",
    "$$\n",
    "- Z-score 标准化\n",
    ">$$\n",
    "x'=\\frac{x-{\\text{mean}}(x)}{\\sigma}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0,1标准化又称离差标准化,作用是将数据集内的所有数据缩放到[0,1]的范围之内。\n",
    "- Z-Score标准化，作用是将数据集转化为均值为0，标准差为1的标准正态分布数据。但如果原始数据和标准正态分布相差很远，那么结果可能会非常糟糕。\n",
    "\n",
    "代码如下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0-1标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据：\n",
      "[[ 7 45 19 40 40]\n",
      " [46 34 38  5 10]\n",
      " [39 22 22  9 27]\n",
      " [40 49  2 26 30]\n",
      " [ 2 11  7  1 24]]\n",
      "0-1标准化后数据\n",
      "[[0.11363636 0.89473684 0.47222222 1.         1.        ]\n",
      " [1.         0.60526316 1.         0.1025641  0.        ]\n",
      " [0.84090909 0.28947368 0.55555556 0.20512821 0.56666667]\n",
      " [0.86363636 1.         0.         0.64102564 0.66666667]\n",
      " [0.         0.         0.13888889 0.         0.46666667]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "data_Standardization=np.random.randint(50,size=(5,5))\n",
    "#使用预处理中的MinMaxScaler生成一个标准化对象\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#调用这个对象对数据进行标准化操作\n",
    "data_scaled = min_max_scaler.fit_transform(data_Standardization)\n",
    "print('原始数据：')\n",
    "print(data_Standardization)\n",
    "print('0-1标准化后数据')\n",
    "print(data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-score标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据：\n",
      "[[ 7 45 19 40 40]\n",
      " [46 34 38  5 10]\n",
      " [39 22 22  9 27]\n",
      " [40 49  2 26 30]\n",
      " [ 2 11  7  1 24]]\n",
      "Z-score标准化后数据\n",
      "[[-1.07418496  0.9038322   0.11115313  1.62632665  1.41914037]\n",
      " [ 1.0416339   0.1271014   1.61965985 -0.76533019 -1.66594739]\n",
      " [ 0.66187154 -0.72024128  0.3493384  -0.49199798  0.08226901]\n",
      " [ 0.7161233   1.18627976 -1.23856342  0.66966391  0.39077778]\n",
      " [-1.34544378 -1.49697208 -0.84158796 -1.0386624  -0.22623977]]\n",
      "特征均值\n",
      "[-4.44089210e-17 -1.77635684e-16 -1.55431223e-16  4.44089210e-17\n",
      "  7.21644966e-17]\n",
      "特征方差\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "data_scaled = preprocessing.scale(data_Standardization)\n",
    "print('原始数据：')\n",
    "print(data_Standardization)\n",
    "print('Z-score标准化后数据')\n",
    "print(data_scaled)\n",
    "print('特征均值')\n",
    "print(data_scaled.mean(axis=0))\n",
    "print('特征方差')\n",
    "print(data_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到均值非常接近0，方差为1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里需要注意的是，如果输入矩阵，sklearn的预处理操作默认是对列进行的，这也刚好是我们需要的——我们通常是对特征进行标准化处理，而每个特征在数据集中的表现就是列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 独热编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "独热码的实现和标准化比较类似，可以使用pandas自带的get_dummies函数来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=pd.DataFrame({'年级':['大一','大二','大三'],'学生数':[100,200,300]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学生数</th>\n",
       "      <th>年级_大一</th>\n",
       "      <th>年级_大三</th>\n",
       "      <th>年级_大二</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   学生数  年级_大一  年级_大三  年级_大二\n",
       "0  100      1      0      0\n",
       "1  200      0      0      1\n",
       "2  300      0      1      0"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到已经转换成功，数据适合输入skleanr等模型进行后一步计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
