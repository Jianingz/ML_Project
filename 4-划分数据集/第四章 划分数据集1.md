# 第四章 划分数据集 

标签（空格分隔）： 未分类

---
## 4.1 训练集/测试集
### 4.1.1 为什么划分
　　在没有机器学习和深度学习的时候，计算机没办法像人类一样智能的识别出事物，所以科学家们也在一直在这方面进行研究与探索。目前为止，他们也已经找到了一些方法，比如机器学习中的SVM以及深度学习，去让计算机能够拥有识别能力。  
　　那么有的读者就会问了，到底怎样利用数据去学习呢？举个简单的例子，假如我们需要去识别哈士奇这个品种的狗，所以我们需要用很多品种的狗的图片进行训练，这里的图片中的信息就可以理解为训练集。每个品种的狗的特征都不一样，他们的毛色、眼睛颜色、眼睛形状、体型等等特征造就了不同品种的狗。正是利用这些信息（数据）去学习哪些是哈士奇特有的特征，哪些不是它特有的特征。学习之后，再放入训练集没有的图片去测试，计算机就会利用已经学习到的哈士奇特有的特征去判断这个测试图片中的狗是否属于哈士奇。 
　　训练集的作用是用来找寻数据之间潜在关系的一组数据，当我们找到数据集中数据之间的关系之后，再用测试集去验证这个关系的强度，也就是预测的准确性。训练集和测试集之间是独立的，也就是他们之间没有重合的数据。并且二者的概率分布是一致的。
### 4.1.2 划分比例  
　　我们把将数据集划分成训练集、测试集这两部分的方法也叫Hold-out Validation。Hold-out Validation的原理很简单，并且它的运行速度也是十分快速的。但是由于它是基于强假设的，所以缺乏有效的统计特征，它的验证结果的可靠性就不是很高，同时也很难在单个数据集上计算方差信息与置信区间。所以一般来说如果数据及足够大，那么就可以用这种划分数据集的方法，那么预测值也相对来说比较可靠。
　　在几年前，科学家们还在运用一些传统方法的时候，往往按照7:3或者8:2的比例来划分训练集和测试集。而当数据量不大的时候，往往要再加一个验证集，它们三个的比例一般是训练集：验证集：测试集=6:2:2，如下图所示。 
![](/resource/4.1.1_1.png?raw=true)

　　然而到了现在这个时代，数据则很轻易就上升到了百万、千万的级别，那么这时就不需要那么多的验证集和测试集了。假设有200W的数据，只需要拿出1W的数据做验证集、1W的数据做测试集就可以了。也就是当数据集很大的时候，训练集、验证集、测试集的比例可以是98:1:1，也可以是998:1:1，具体比例可以根据实际情况来划分。
　　在将数据集划分之后，我们选择一个我们认为适合给定问题的学习算法。首先我们需要设定超参数，超参数是我们学习算法的参数，它也叫元参数。我们必须手动设定这些超参数值，因为学习算法不会从训练数据中学习这些值。由于在模型拟合过程中没有学习超参数，所以我们需要某种“额外的过程”或“外部循环”来分别优化它们——这种坚持的方法不适合这个任务。因此我们可以利用现有的机器学习库、经验或者现成算法的默认参数，来设定这些固定的超参数值。	
　　接下来的一个问题就是怎样才能说明模型的性能是“好”的呢?这就是独立测试集发挥作用的地方。由于学习算法以前从未“见过”这个测试集，因此它应该对它在未见的新数据上的性能提供一个相对公正的估计。现在，我们使用这个测试集并使用模型来预测类标签。然后，我们将预测的类标签与正确的类标签进行比较，以估计模型的泛化精度或误差。
### 4.1.3 层次，非层次划分 
　　如果一个数据集在随机抽样之前有很高的等级不平衡，那么在最坏的情况下，经过随机抽样，测试集可能不包含任何少数类的实例，也就是这会严重增加预测结果的偏差。因此,推荐的做法是用分层的方式划分数据集。在这里，分层仅仅意味着我们随机地分割一个数据集，这样每个类在结果子集(训练和测试集)中得到正确的表示，换句话说，分层是在结果子集中保持原来的类比例的方法。也就是如果样本集中存在好几个类别，那么在划分训练集、测试集的时候也要按照类别的比例去划分。那么我们也就知道，非层次划分就是不需要按照类别比例划分，而是随即在所有数据集中抽取即可。比如有两类，15个白球，5个黑球。那么层次划分就是按照80%、20%的比例从白球、黑球中分别抽取训练集、测试集，将白球的训练集和黑球的训练集合在一起作为总训练集，同理总测试集。非层次划分就是把白球和黑球合在一起，在这20个球里面按照80%、20%的比例去划分训练集和测试集。
　　非层次划分如果只做一次分割，它对训练集、验证集和测试集的样本数比例，还有分割后数据的分布是否和原始数据集的分布相同等因素比较敏感，不同的划分会得到不同的最优模型，而且分成三个集合后，用于训练的数据更少了。
### 4.1.4python代码及常用库

　　举个例子，总共有1000条数据
```
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn import datasets
from sklearn import svm
iris = datasets.load_iris()
iris.data.shape, iris.target.shape
((1000, 2), (1000,))

```
　　用 train_test_split 来随机划分数据集，其中 20% 用于测试集，有 200 条数据，80% 为训练集，有 800 条数据：
```
 X_train, X_test, y_train, y_test = train_test_split(
iris.data, iris.target, test_size=0.2, random_state=0)
	
 X_train.shape, y_train.shape
((200, 2), (200,))  
X_test.shape, y_test.shape
((200, 2), (200,))

```
用 train 来训练，用 test 来评价模型的分数。
```
clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
clf.score(X_test, y_test)                            
0.96...

```

## 4.2 交叉验证

### 4.2.1交叉验证简介
　　交叉验证的英文全称是Cross Validation，它是不同于Holdout Validation的另一种划分数据集的方法。交叉验证的基本思想是在某种意义下将原始数据(dataset)进行分组,一部分做为训练集(train set),另一部分做为测试集(validation set or test set),首先用训练集对分类器进行训练,再利用测试集来测试训练得到的模型(model),以此来做为评价分类器的性能指标。
　　交叉验证背后的主要思想是，数据集中的每个示例都有被训练和测试的机会。k -fold交叉验证是交叉验证的一种特殊情况，我们在数据集中迭代k次。在每轮迭代中,我们将数据集分为k个部分:,k-1个部分合并成一个训练子集，剩下的一个部分作为测试集。
　　交叉验证其实分为两类，一类叫k折交叉验证法（k-fold Cross Validation）,还有一类叫留一交叉验证法（Leave one out cross validation）。后者可以理解为前者的特殊情况，即假设样本集中有m条样本，而当k=m时，所用的方法就叫留一交叉验证法。这种方法的每轮迭代中，测试集都只有一条样本，总共要进行m轮迭代，这个方法用于训练的数据只比整体数据集少了一个样本，因此最接近原始样本的分布。但是由于模型的数量与原始数据样本数量相同，所以训练复杂度十分大，因次如果在原始数据极度缺乏的情况，可以使用这种方法，普遍情况下还是使用k折交叉验证法比较多。
### 4.2.2目的
　　我们为什么要用交叉验证法呢？
　　因为当数据集较小的时候，我们通过交叉验证相当于“扩大”了数据集，也就在一定程度上避免了过拟合，还可以从有限的数据中获取更多的有用信息。另外，由于交叉验证是从很多不同的方向去学习数据，所以交叉验证就能避免陷入局部最小值。
　　这三个原因就是使用交叉验证的目的。
### 4.2.3划分的原理详解图
　　如下图所示,它表示了5折交叉验证。
　　![](/resource/4.2.3_1.png?raw=true)
　　如上图所示，在k折的交叉验证中，这个过程将生成k个不同的模型，这些模型的训练集是不完全相同但部分重叠的，并在不重叠的验证集上进行评估。最后，我们计算交叉验证性能的算数平均值作为整个模型的性能的最终值。其详细步骤如下表所示：
　　![](/resource/4.2.3_2.png?raw=true)
　　　
### 4.2.4层次，非层次划分
　　交叉验证中的层次/非层次划分的含义和4.1中的一样。在交叉验证中的层次划分就是在每一份子集中都保持和原始数据集相同的类别比例。
### 4.2.5数据量和划分叠数的关系
　　5折交叉验证是最常用的，当然，当数据量较大的时候，我们也可以选择3折交叉验证；当数据量较小的时候，我们可以选择10折交叉验证。
### 4.2.6python代码及常用库
　　sklearn更新之前交叉验证在cross_validation模块里面，更新之后在model_selection里面.最简单的方法是直接调用 cross_val_score，这里用了 5 折交叉验证：
　　第一步就是加载数据集
```
import numpy as np 
from sklearn import cross_validation
from sklearn import datasets
from sklearn import svm
iris.data.shape, iris.target.shape
((150, 4), (150,))

```
经过第一步之后，数据集特征和类标签分别为iris.data, iris.target，第二步开始交叉验证。
```
X_train, X_test, y_train, y_test = cross_validation.train_test_split(
...     iris.data, iris.target, test_size=0.4, random_state=0)
X_train.shape, y_train.shape
((90, 4), (90,))
X_test.shape, y_test.shape
((60, 4), (60,))
clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
clf.score(X_test, y_test)                           
0.96...

```
其中第七行的clf是分类器的意思，可以自己任意选择，举个例子如果选择随机森林：
```
clf = RandomForestClassifier(n_estimators=400)
```




##  4.3 项目实例运用






