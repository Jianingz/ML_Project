## 7.1 未完
　　神经网络作为人工智能的底层模型，在大数据时代应用十分普遍，很多应用都是基于神经网络的。比如模式识别、自动控制、深度学习等等。那么神经网络到底是用来干什么的呢？其实，它最常用的用途就是用来分类，在这里我们举几个直观的例子来说明：
 
 - 非法广告的识别：如何判断一个广告是非法广告呢？一般需要将广告中出现的词汇提取出来，然后通过机器的判别，来决定这个广告是不是合法的。
 - 疾病诊断：，医院中的每一项检查都可能包含很多小“项目”，比如通过化验血、小便、以及肝功能、B超等检查，然后将检查结果送给机器去诊断，最后得出病人可能患有哪种疾病。
 - 狗品种分类：将许多品种的狗的图片送到机器中去训练，机器学习到哪种是哈士奇、泰迪或者雪纳瑞。
　　这种机器就叫做分类器。分类器的输入是一个向量，这个向量也叫做特征向量，就是向量中包含的是能代表事物特点的特征。分类器的输出是由数值来表示的。
　　比如在非法广告识别中，机器里本身就有一个“非法词库”，比如一些敏感词或者有色情意味的词，当把广告中的词提取出来之后，如果这些词在词库中出现，那么这个词在向量中对应的数字即为1，如果词库中没有该词，向量中对应的数字即为0；它的输出可以由0或者1表示，0就是代表非法广告，需要在最快时间下线，1代表合法广告，可以在广告位上展示。
　　在疾病诊断中，分类器的输入就是许许多多化验指标组成的向量；它的输出可以由0、1、2、3等数值表示，0可以代表身体健康，没有疾病，1可以代表有高血压，2可以代表糖尿病······
　　在狗品种分类中，分类器的输入是长度与图片像素和通道有关的向量，比如每一个图片都是像素为640*480的红绿蓝三通道图片，那么这个向量的长度就是640*480*3；同样输出是由数值表示，0代表哈士奇，1代表泰迪，2代表雪纳瑞······
　　分类器的目的是让分类尽可能的准确，一般我们会收集样本，并且已知这些样本的分类结果，这个分类结果也叫“标签”，换句话说就是将这些训练集打上标签。然后将它们“喂到”机器中去学习，也就是训练分类器，然后经过不断地调整优化，最后我们就可以将未知分类的样本输入到分类器中去预测分类结果了。
### 7.1.1	神经元与感知器
　　一直以来，人们希望可以模拟人类的大脑，以此创造出可以思考的机器。那么，人的大脑为什么能够进行思考呢？医学家发现，这是因为人体中含有无数个“神经网络”。
　　
　　上图所示就是神经元的具体结构。神经元又叫神经细胞，外部刺激可以通过神经末梢的传导转化为电信号。神经中枢是由许许多多的神经元组成的，神经中枢对各种信号进行综合并作出相应的指令判断，而人体就依据神经中枢发出的指令做出相应的反应。
　　现在既然已经明白了人体中神经元的构造，那么如果能够构造出人造的神经元，就能构造出人工神经网络，这样就能模拟出人的大脑进行思考。在五十多年前的上世纪六十年代，有人提出了历史上最早的“人造神经元”模型，这个模型也叫“感知器”，伟大的是一直到现在这个概念依然沿用。
　　1958年，科学家Rosenblatt提出了“感知器”的概念（有些文献也叫作“感知机”），并定义感知器是由两层神经元组成的神经网络。这位伟大的科学家在当时甚至还现场演示了感知器学习识别简单图像的操作过程，作为当时第一个可以像人类一样“学习”的人工神经网络，这个创举在那时引起了巨大的反响。伟大的是，一直到现在这个概念依然沿用。
![](/resource/7.1.1_1.png?raw=true)
　　上图的圆圈就表示感知器，感知器的左边是输入，输入可以是一个也可以是多个，输出只有一个。神经元就相当于感知器，外部刺激相当于输入，外部刺激通过神经末梢的传导，输出为电信号的形式。
　　下面对感知器举一个例子，小张每周末要去户外打篮球，但是由于各种因素，小张不一定每周都去，影响小张去打球的因素有以下几点：
　　（1）	会不会下雨
　　（2）	会不会太晒
　　（3）	作业有没有写完
　　以上三个因素就构成了感知器的三个输入，最后的决定（去或者不去）就是输出。现实生活中，各个因素在人的心中的重要度很可能是不一样的，这里的重要度我们称之为“权值”并且一般来说所有权值之和为1。比如当不会下雨并且作业写完了的情况下，就算有一点晒，小张也会去打球；但是如果不晒并且作业写完了但是下了雨，校长一定就不回去打球。比如在小张心中，这三个输入的权值分别为0.6、0.1、0.3。这时还需要确定一个阈值k，如果最终输出大于阈值k，那么小张就会去打球。并且输出数值越大，表示想去打球的可能性越大。
　　上面的决策过程用数学公式表达如下：
![](/resource/7.1.1_2.png?raw=true)
　　也可以表示为：
![](/resource/7.1.1_3.png?raw=true)
　　其中ω表示决定输出的各个因素所对应的权值，x表示各个因素。
　　这里有人会问，如果输出只有两类——0或者1，当权值和阈值发生变化时，输出的敏感性会很低，所以当输出希望是一个连续的数值，而不是用二分类表示的时候，这是我们可以将其转换成一个连续的函数。
　　令z=ωx+b,这里引入sigmoid函数：
![](/resource/7.1.1_4.png?raw=true)
![](/resource/7.1.1_5.png?raw=true)
　　Sigmoid函数如上图所示。当感知器训练得非常成熟时，也就是z区域正无穷的时候，那么σ（z）→1；当感知器十分“青涩”没训练好的时候，那么σ（z）→0。也就是如果我们将σ（z）作为输出，输出结果就可以表示为连续函数了。
### 7.1.2神经网络简述
　　在现实生活中，一个决策模型可能包含很多感知器，也可以理解为决策模型是由感知器组成的多层网络。如下图所示，这个决策模型是由三层感知器组成的，最左边的一层感知器是输入层，它用来接收外部的输入，经过传导输出的内容作为第二层感知器的输入，直到上层感知器输出，第二层也叫隐藏层。第三层是输出层。这里每个感知器的输出依然只有一个，只不过是可以发送给多个感知器作为输入。可以直观的看出，输入层有四个单元，隐藏层有三个单元，输出层有两个单元。
![](/resource/7.1.2_1.png?raw=true)
　　搭建一个完整的神经网络需要满足以下三个条件：
　　（1）输入和输出
　　（2）权值和阈值
　　（3）多层感知器的结构
　　权值ω和阈值k都是人为确定的，但是怎么才能找到最合适的值呢？一般使用试错法，就是在其他参数不变的条件下，对ω或者k作出轻微的变动，记作∆ω或者∆k，接着观察输出的变化，不断的重复这个步骤，知道得出最适合的权值和阈值。这个过程就是模型的训练过程。
　　在构造一个神经网络的时候，输入层和输出层的感知器数量是一定的，在这里感知器也可以称之为“节点”，而隐藏层的节点数是可以变化的。整个神经网络的结构和箭头指向表示着预测过程中数据的流向，预测过程中数据的流向和大小与实际训练时候的情况可能有所不同。在训练神经网络的时候，我们的目的就是要找到最合适的权值，在图中就是表示为连接线的“大小”。
　　在训练过程中，感知器的权值是通过训练也就是不断调整得到的，这和神经元有所不同。我们可以把感知器看做一个逻辑回归模型，用来完成线性分类的任务。在这里我们用决策分解来表现分类的效果。当数据是二维平面时，可以用一条一维的直线将数据一分为二；当数据的维度是三维的时候，可以用一个二维的平面将数据分成两类······以此类推，当数据是n维的时候，可以用（n-1）的超平面将数据分为两类。如下图所示，用一条直线对二维平面进行决策分界。
![](/resource/7.1.2_2.png?raw=true)
　　2006年，Hinton在全世界非常有名的科学期刊《Science》上发表了一篇论文，在这篇论文中他提出了“深度训练网络”的概念。与之前的训练方式不同的是，“深度训练网络”中有一个步骤叫“预训练”（pre-training），这一步先在神经网络的权值最优解“附近”找到非常接近最优解的一个值，然后再使用“微调”的方法对整个神经网络进行训练。这两个技术大量减少了训练的时间。Hinton还将“深度学习”这个名字赋予给类似于这样的对多层神经网络进行训练优化的过程。
　　多层神经网络包含至少一层隐藏层。单层感知器只能学习线性函数，而多层感知器也可以学习非线性函数。线性代数是神经网络的重要理论基础之一，然而除了线性网络，神经网络中还有大量的非线性运算。比如对于隐藏层中的神经元，它的值再传给输出层之前，会先经过一次非线性运算。这里的非线性运算也叫“激活函数”，激活函数有很多种，最经典的就是sigmoid函数。
　　也许读者会问，为什么要引入非线性运算呢？最简单直接的原因就是，根据矩阵乘法的结合性，三个3*4与4*2与2*5的矩阵相乘相当于一个3*5的矩阵，那么如果多个线性运算层直接相连，就相当于只进行了一层线性运算，多层次的网络结构就失去了意义。
　　如果出现如下图所示的数据集，线性运算就无法“一刀”将之分割，而非线性运算就可以将直线变为曲线，把数据集分为两类，如下图所示。
![](/resource/7.1.2_3.png?raw=true)
