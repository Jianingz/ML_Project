# 7.3 卷积神经网络

## 目录
- 卷积运算
- 网络结构
- 卷积层
- 池化层
- 经典卷积神经网络列举
- Tensorflow实现卷积神经网络
- 卷积神经网络与迁移学习


卷积神经网络(Convolutuional Neural Network,简称CNN)，是深度学习技术中最具代表性的一种经典神经网络。卷积是一种特殊的线性运算，是值定义在两个联系实值函数的数学操作。而卷积神经网络就是指在网络结构中至少有一层使用了卷积运算来代替一般的矩阵乘法运算的神经网络。CNN应用非常广泛，尤其是在计算机视觉、图像识别等领域都有着出色的表现，获得了巨大成功。本节将对卷积神经网络做一个简介。


## 7.3.1 卷积运算

卷积操作是定义在两个连续实值函数上的数学操作，为了方便读者理解卷积，通过下面一个例子引出卷积的定义。(本例摘自参考文献《深度学习》)。

假设正在监控一艘自带激光传感器的宇宙飞船，传感器在任意时刻t都能产生一个输出x(t)，x(t)表示飞船在任意时刻t的位置，x和t都是实值。由于在实际过程中有噪声，传感器会受到不同程度的信号干扰，为了更加准确获得飞船的位置，可以对捕获的位置数据进行加权平均处理。显然，时间越近，捕获的数据与实际值约相关，所以不妨将最近的测量数据赋予更高的权值。我们可以通过加权函数w(a)实现，其中a表示测量结果距离当前时刻的时间间隔。这样加权平均后的飞船位置计算公式为：
![](/resource/7.3.1_1.jpg?raw=true)

这个运算就是连续卷积(convolution)的含义，可以表示为一个函数(w)在另外一个函数(x)上的加权叠加，通常被记为：
![](/resource/7.3.1_2.jpg?raw=true)

通常，我们把函数x称为输入(input)，函数w称为核函数(kernel)，输出则称为特征映射(feature map)。

卷积操作满足线性运算的三大规律，即交换律，分配律和结合律。令p=t-a，对于任意的t，当a趋于正无穷时，p趋近于负无穷，反之当a趋于负无穷时，p趋近于正无穷。从而有：
![](/resource/7.3.1_6.jpg?raw=true)

卷积的分配率和结合律可以表示为：
![](/resource/7.3.1_7.jpg?raw=true)

在上述例子中，激光传感器产生的是一个连续的数据，是随时间t不断变化的数值。但是在计算机的业务场景中，连续卷积无法实现，必须离散化，也就是以一定的时间间隔记录相邻的两个数据。还是借用上面的例子，如果激光传感器每隔时间间隔t(t为整数)发送一次数据，那么定义离散形式的卷积为：
![](/resource/7.3.1_3.jpg?raw=true)

如图所示，是二维空间上应用离散卷积的例子，离散卷积可以看作矩阵的乘法，卷积核是一个2*2的二维结构，将卷积核作用在输入数据上，按照从上到下，从左到右的顺序进行运算。
![](/resource/7.3.1_4.jpg?raw=true)

通过上面的例子，可以看到离散卷积本质是有加权的线性运算。在图片识别等领域中，通常也会配置一个宽高为w*h的卷积核，假设输入的图片大小为m*n。卷积核按照从上到下，从左到右的顺序扫描整个图片，会得到一个新的映射空间，其大小为(m-w+1)*(n-h+1)。

图展示了利用卷积核提取图像的特征，该卷积核是一个3*3的带权值的三维结构，被称为高斯-拉普拉斯算子，是在图像处理中非常著名的滤波器。
![](/resource/7.3.1_5.jpg?raw=true)


## 7.3.2 网络结构

在深入介绍卷积神经网络之前，我们先对CNN与传统的MLP在网络结构的异同点做一个简单的梳理。

首先是两者的相同点：

	- 两者都是多层的网络结构，每层的神经元有且只与前后层的神经元相关联，与非相邻层的神经元没有联系。此外每个神经元从上一层的神经元中接受数据，通过线性加权后，选择合适的非线性激活函数输出。
	- 两个都是从输入层输入数据，在输出层定义损失函数，并通过最小化损失函数调整权重以期得到最优解。

两者最大的区别在于MLP是一个全连接的网络，如图所示，传统神经网络每层的神经元的输入来自上一层所有神经元的数据，以此类推不断向后延伸。但是显然这样做有缺陷，比如局部最优解，梯度消失，可拓展性差，计算量大等。
![](/resource/7.3.2_8.jpg?raw=true)


CNN的出现在一定程度上对上述缺点做了改进，避免操作所有神经元，实现了端对端的表示学习思想。如图是一个典型的CNN神经网络结构，我们可以看到，卷积网络在进入全连接层之前，已经经过多个卷积层和池化层的处理，从而优化了网络结构。
![](/resource/7.3.2_9.jpg?raw=true)

简要概述CNN网络中重要的网络节点结构，详细内容将在后面各节中介绍。

	- 卷积层(Convolutional Layer)：CNN网络的核心结构之一，通过局部感知和参数共享两个原理，实现对高维数据的降维，从而提取图像特征。
	- 激活层(Activation Layer)：其作用是对上一层的线性输出做非线性化处理，之前章节介绍的激活函数，比如sigmoid激活函数，ReLU激活函数等都可以使用。
	- 池化层(Pooling Layer)：CNN网络的核心结构之一，可以把降维后的数据再次缩减数据规模，并且对输入数据具有局部线性转换的不变性，增强网络泛化能力。
	- 全连接层(Full Connected Layer)：经过卷积层和池化层的多层处理后，数据维度已经大幅下降，可以通过前馈网络处理；此外全连接层的输入是之前数据多次提炼后的抽象，比直接使用原始数据作为输入拥有更好的预测结果。


### 7.3.3 卷积层

卷积层是CNN的核心，设计卷积层的核心目的在于降低数据维度，此外还有其他方面的考虑。所以在展开对卷积层的描述前，不妨先了解其设计目的。

目的1：实现对输入数据的降维

传统的神经网络有先天的缺陷，对数据规模非常敏感。一旦数据规模较大，由于每层的神经元数值的计算需要上一层所有神经元的参与，必然会造成计算缓慢甚至无法得出数据。比如传统的神经网络处理图片信息时，假设输入图片是1000*1000*3的RGB图像，那么输入层就有3*10^6的神经元，假设只有一层隐藏层，也拥有3*10^6的神经元，那么对于全连接的神经网络来说，从输入层到隐含层的参数就会有(3*10^6)^2=9*10^12个。可以看出，随着隐藏层数和输入图像复杂度的增加，训练参数将非常耗时甚至无法进行，所有需要对数据进行降维。

目的2：模拟生物学理论

早在19世纪60年代科学家提出了感受野的概念。当时科学家通过对猫的视觉皮层细胞的研究发现，每个神经元只会处理一小块区域的图像信息，这就是所谓的感受野。随后Hubel和Wiesel的研究表明，生物的视觉系统存在着复杂的细胞分布，当接受到外界的输入信号后，不同细胞对输入的不同部分具有局部敏感性。比如一些细胞对颜色数据敏感但是对边缘特征不敏感，这些细胞可以识别出图像的颜色但是却无法识别物体的边缘。再比如一些细胞对运动数据敏感但是对纹路数据不敏感，这些细胞可以识别整个视野的运动特征并忽略物体的纹路。视觉系统通过一个个感受野扫描整个视野，抽取特征信息，然后在通过对抽象出的特征进行组合，达到全局处理的效果。这也是神经网络的生物学基础。

目的3：提取深层特征

长期以来，科学家都从数学的角度强调卷积层的重要性，直到2014年，Zeiler和Fergus提出通过反卷积操作可视化每一层提取的特征。通过可视化，可以形象观察到CNN如何从提取第一层简单的边缘特征，在通过不断的抽象和组合出负责的形状特征。通过调整卷积核的参数，还可以看到CNN网络提取出了不一样的特征。如果再通过多个卷积核的组合，还能进一步加强CNN网络的表达能力，抽象出更复杂更贴近实际的特征，所以看出提取的深层特征对于图像的表征有非常明显的作用。

卷积层由三个部分组成，通过卷积核，不但可以提取出深层特征，还能极大程度减少参数数量，从而提高训练效率。

1.局部感知

在处理例如图像，音频等高纬数据时，如果神经元采用全接连的方式会导致训练时间和空间代价惊人。但是根据生物学中感受野的研究表明，动物对外界的认知并不是宏观的，一蹴而就的，相反是一个从局部到整体的过程。而图像的空间联系特征也是如此，局部之间的像素联系紧密，共同表达一个主题，距离较远的像素关联性就比较弱。所以，神经元并不需要把所有像素都做关联，只需要对局部的内容做感知去抽象即可。具体来说，就是在构建卷积层时，这一层中的每一个神经元并不需要与上一层的所有神经元发生联系，只需要一部分神经元即可。这种联系方式可以成为局部感知。

2.空间位置排列

卷积层的结构主要由四个超参数决定，包括卷积核的大小，卷积核的数量，步长和补零。下面围绕这四个参数详细介绍神经元是如何与输入层进行交互的。

卷积核的大小：卷积核的大小本质讲就是局部感知野的大小，卷积核是一块子区域，如图所示，定义了一个大小为5*5*3的卷积核，需要强调的是卷积核的大小主要针对宽度和高度，深度与原始数据保持一致。卷积层的每一个神经元只需要与卷积核对应的区域相关联。
![](/resource/7.3.3_10.jpg?raw=true)

卷积核的数量：每一个卷积核只能提取图像的一部分特征，但是显然这样做是不够的，提取的特征也不够充分，所以可以添加多个卷积核提取多重特征，每一个卷积核提取的特征都各有侧重点，这样做可以更加丰富的表征图像特征。而每一个卷积核与原始输入数据完成卷积操作后得到的神经元集合，就是特征图谱。

步长：指定卷积核在输入数据上移动的步幅，假设步长为s，那么卷积核在每一步会跳跃s个像素。一维数据为例，图X和图X分别展示了步幅为1和2的时候对应的神经元，假设卷积核大小为3，权重值为(1，0，-1)。
![](/resource/7.3.3_11.jpg?raw=true)

补零：在处理边界时常用到补零。由于卷积核的大小不一定被输入数据整除，必然有卷积核无法覆盖的地方。为了防止信息丢失，可以采用补零的策略，即在边界处适当补充零使得边界处的大小与卷积核吻合。例如，对于输入向量(0，4，1，-4，1，-3)，卷积核为(1，0，-1)，步长为2，那么卷积核不能完全覆盖输入数据。这时可以在原始数据的边界补充零，构造成(0，4，1，-4，1，-3，0)，这样卷积核就可以覆盖所有数据。

综上，构建卷积层时主要考虑卷积核的大小，卷积核的个数，步长和补零个数这四个方面。当这四个方面确定后，卷积层的结构也就唯一确定了。以一维数据为例，假设输入数据大小为w，卷积核的大小为f，步长为s，补零个数为p，那么对于每个卷积核，它与输入数据进行卷积运算后，得到的特征图谱包含的神经元个数为：
![](/resource/7.3.3_12.jpg?raw=true)

对于高纬数据，每一维度都可以参照上述公式计算。

3. 参数共享

神经元的参数需要实现共享，如果不共享会出现什么问题呢？假设这样一个场景，一个原始图像大小为64*64*3，超参数设置为，100个卷积核，每个卷积核的大小为5*5*3，步长为1，没有补零。根据公式计算，可以得出每个卷积核对应的特征图谱含有的神经元个数为60*60，那么每个卷积核对应的参数设置就为60*60*5*5*3，对于所有的100个卷积核来说，总的权重数为60*60*5*5*3*100=27000000，这个数量级虽然比全接连的神经网络的参数量下降了很多，但是数据规模仍然十分巨大，计算开销也很可观。但是如果采用参数共享的方式，就可以完美的解决上述出现的问题。

参数共享是基于这样一个假设：数据在某个位置(x1,y1)的统计特性，同样适用于其他任意位置(x2,y2)。所以对于同一个卷积核，它的特征参数应该同样适用其他所有位置，也就是所每一个卷积核对应生成的特征图谱神经元都共享同一个参数列表。基于这个思想，我们可以实现参数共享，用相同的参数来连接输入层和卷积层。经过这样处理后，上面场景中参数的数目为5*5*3*100=7500。

虽然参数共享大大降低了卷积层和输入层之间的权重参数，但并没有改变前向传播的速度。


### 7.3.4 池化层

池化层，有被称为子采样层，是卷积神经网络中又一重要设计。当输入数据经过卷积层提取出特征图谱后，需要在进入下一层网络前，先进行池化层的操作。也就是说池化层是夹在连续的卷积层中间，主要用于压缩数据和参数的量，减小过拟合。

池化层函数是一个统计函数，其原理简单描述为，假设输入数据的大小为W*H，给定一个池化滤波器，大小为w1*h1。池化层函数会按照w1*h1为单元，考察输出函数在这个子区域内的统计特征。常见的统计特征有最大值，均值，L2范数，加权平均等指标。

![](/resource/7.3.4_14.jpg?raw=true)


最常见的池化层函数式最大池化层函数和平均池化层函数。以一维数据(1，3，2，4)为例，描述两者在前向传播和反向传播中的运算过程。

1.最大池化函数(max pooling)

前向传播操作中，会选择最大值作为输出结果，forward(1,3,2,4)=4。

后向传播操作中，最大值元素不变，滤波器中其他元素补零，backward(4)=(0,0,0,4)。

2.平均池化函数(average pooling)

前向传播操作中，会选择平均值作为输出结果，forward(1,3,2,4)=2.5。

后向传播操作中，所有值都为平均值，backward(2.5)=(2.5,2.5,2.5,2.5)。

![](/resource/7.3.4_13.jpg?raw=true)


池化层的作用主要是两个：

1.池化操作能保持局部线性变换的不变性。也就是我们在图像处理中经常提到的特征的尺度不变性，池化操作就是图像的resize，平时一张狗的图像被缩小了一倍我们还能认出这是一张狗的照片，这说明这张图像中仍保留着狗最重要的特征，我们一看就能判断图像中画的是一只狗，图像压缩时去掉的信息只是一些无关紧要的信息，而留下的信息则是具有尺度不变性的特征，是最能表达图像的特征。具体讲，就是如果输入数据进行线性变换，例如平移选择等操作，经过池化层后的输出数据没有变换。局部线性变换的不变性在一些场景下发挥重要作用。假设图片识别的业务场景中我们只关心判断一个物体是否存在，而不关心其具体位置。比如人脸识别，我们只需要提取出人脸的信息，不关心人脸在图像中的具体位置。

2.池化操作可以帮助进一步减少参数量，我们知道一幅图像含有的信息是很大的，特征也很多，但是有些信息对于我们做图像任务时没有太多用途或者有重复，我们可以把这类冗余信息去除，把最重要的特征抽取出来，这也是池化操作的一大作用。假设卷积层输出数据的大小是10000*10000，如果池化层设置大小为2*2，那么经过池化层处理后输出数据的大小为5000*5000，也就是说减少了4倍的数据量。

3.在一定程度上防止过拟合，更方便优化。


### 7.3.5 经典卷积神经网络列举

本节将介绍四种经典的卷积神经网络，分别是AlexNet，VGGNet，Google Inception Net，ResNet。这四个网络在网络结构的深度和复杂度依次递增。它们在各自的使用年代率先使用了新的网络结构，在ILSVRC比赛中都获得了好成绩，对卷积神经网络的发展起到了非常大的推动作用。

ILSVRC是非常著名的计算机视觉比赛，它的数据集来自ImageNet。ImageNet是2007年由斯坦福大学华人教授李飞飞创办，李教授所在实验室收集了超过150万张带有标记的高清图片，总共拥有22000类别，其中约有100万张标注了图片中主要物体的定位边框，这些带有标记的图片是为了计算机视觉模型训练所用。根据李教授介绍，其项目灵感来自模拟人类世界婴儿通过视觉学习世界的方式，他们假设婴儿的眼睛就是一台照相机，根据人类眼球转动一次的平均时间大概是200ms，所以按照这个时间间隔拍照一次，那么一个三岁大的孩子就会看到上亿张图片，ImageNet项目从网上下载了近10亿张图片，使用亚马逊的土耳其机器人平台实现众包的标注过程，来着167个国家的5万位志愿者一起帮忙筛选分类并完成标注。而每年的ILSVRC比赛所用的数据集为1000个类别，大概120万张图片，比赛一般用top-5和top-1分类错误率作为模型性能的评测指标。

1.ALexNet

2012年，Hinton的学生Alex Krizhevshy提出了卷积神经网络模型AlexNet。AlexNet神经网络如图所示，共有8个需要训练参数的层，包括5个卷积层和3个全连接层，在其中3个卷积层后连接了最大池化层。AlexNet总共包含了6亿3000万个连接，6000万个参数和65万个神经元。AlexNet是对LeNet的一种更深更宽的改进，它充分发挥了LeNet的优势并进一步发扬光大，主要用到的新技术点有：
 	- 使用ReLu作为CNN的激活函数，从而替代传统的Sigmoid激活函数。ReLu函数的应用成功解决了Sigmoid函数在深层网络中容易发生梯度弥散的问题。
 	- 训练中使用Dropout随机忽略一些神经元，有效避免了过拟合。AlexNet将其实用化，并证明了有效性。
 	- 在CNN中使用重叠的最大池化。此前CNN中常使用的是平均池化，ALexNet全部使用最大池化，避免了平均池化的模糊化效果。同时ALexNet提出步长比池化核小，这样池化层输出就会发生重叠和覆盖。
 	- 提出了LRN层，对局部神经元的活动创建竞争机制，使其中响应比较大的值更大，抑制其他响应小的神经元，从而提高了泛化能力。
 	- 使用GPU加速神经网络的训练过程。ALexNet使用两块GTX 580 GPU进行训练，GPU之间相互通信，互相访问显存，控制了通信的性能损耗。
 	- 数据增强，随机从256*256的原始图像中截取224*224大小的区域，增强了(256-224)^2=2048倍的数据量。这样做的好处显然大大提高了模型的泛化能力，减轻过拟合现象。

![](/resource/7.3.5_15.jpg?raw=true)

2.VGGNet

VGGNet是由Google DeepMind公司和牛津大学计算机视觉组一起研发的深度卷积神经网络。通过反复堆叠3*3的小型卷积核和2*2的最大池化层，不断加深网络结构，最多可以构筑16-19层深的卷积神经网络，从而实现了性能上的提高，错误率也实现大幅下降。在ILSVRC 2014比赛分类项目中取得第2名和定位项目的第1名。最重要的是，VGGNet具有良好的迁移性，可以通过迁移学习的方式，在其他图片数据集上表现出同样优秀的性能，具有良好的泛化能力。

VGGNet的论文详细阐释了其构成，其结构非常简洁。整个网络都使用同样大小的卷积核尺寸和最大池化尺寸，即全部使用3*3的卷积核和2*2的池化核，通过不断加深网络深度提升性能。VGGNet总有5段卷积，每一段内都拥有2-3个3*3卷积层，为了进一步缩小图片尺寸，会在每段的尾部连接一个2*2的最大池化层。在5段卷积中，每段内部的卷积核数量是相同的。但是不同段之间卷积核数量一般不同，数量会逐渐增多，分别是64-128-256-512-512，最后会叠加三个全连接层。虽然网络深度较深，但是参数的消耗量缺不是很大，参数量主要消耗在全接连层。

![](/resource/7.3.5_16.jpg?raw=true)

3.Google Net

Google Net 首次亮相是在ILSVRC 2014的比赛中并以较大优势取得第一名。Google Net有22层深，但是只有500万的参数量，只有AlexNet参数量的1/12，但是却达到比AlexNet好的多的准确率。Google Net降低参数量，主要是为了以下两点：1.参数越多模型约大，需要提供的训练数据就越多，但是实际情况是高质量的数据是非常稀缺的。2.参数越多，消耗的计算资源就越多，花费的时间和物力成本就多。于是Google Net最大的特点就是控制了参数量和计算量，模型深度更深，表达能力更强。此外取得这么好效果的原因还有1.去除了最后的全连接层，用全局平均化层(即将图片尺寸变为1*1)来代替它。全连接层的参数量占到了VGGNet或ALexNet的80%，所以去掉了全连接层后模型更加轻快，也避免了过拟合。2.巧妙的设计出Inception Module提高参数的利用率。其基本结构如图所示。
![](/resource/7.3.5_17.jpg?raw=true)

Inception Module有4个分支：第一个分支对输入数据进行1*1的卷积，提高网络的表达能力，同时对输出通道升维和降维。第二个分支先使用1*1卷积，在连接3*3卷积，相当于进行两次特征变化。第三个分支类似，先使用1*1卷积，然后连接5*5卷积。最后一个分支是3*3最大池化后直接使用1*1卷积。Inception Module可以让网络的深度和宽度高效率的扩展，提升准确率的同时又不会造成过拟合。

4.ResNet

ResNet(Residual Neural Network)由微软研究院的Kaiming He等4位华人工程师提出，他们团队使用Residual Unit成功训练出了深度为152层的卷积神经网络，并在2015年的ILSVRC比赛中勇夺冠军。ResNet网络允许原始输入信息直接传输到后面的卷积层中。这个灵感来自这样一个现实问题：在不断加深神经网络深度时，会出现一个Degradation的问题，准确率会先上升达到饱和，再持续增加深度则反而会降低准确度。这不是过拟合的问题，因为在测试集和训练集都出现了这样的问题。为了解决这个问题，提出了ResNet。假定某神经网络的输入是x，期望输出是H(x)，如果直接把输入x传到输出作为初始结果，那么此时学习目标函数为F(x)=H(x)-x，这就是一个ResNet的残差学习单元，所以ResNet相当于把学习目标改变了，而是学习一个输入和输出的差值H(x)-x，即残差。

ResNet与普通的直连卷积神经网络最大的区别在于，ResNet有很多旁路的支线将输入直接连到后面的层，后面的层可以直接学习残差，这种结构是shortcut。在ResNet论文中，提出了如图的两层残差学习单元，还有三层的残差学习单元。两层的残差学习单元包括两个相同输出通道数的3*3卷积，而3层残差学习单元使用了1*1的卷积，并且在中间的3*3卷积前后都使用了1*1卷积，实现了先降维再升维的操作。

![](/resource/7.3.5_18.jpg?raw=true)


### 7.3.6 Tensorflow实现卷积神经网络

本节会应该Tensorflow实现一个简单的卷积神经网络，数据集是经典的MNIST。本节构建的神经网络会使用到两个卷积层和一个全连接层，读者可以通过这个例子掌握构建和设计CNN的重点环节。

首先载入MNIST数据集，创建程序入口Interactive Session。
```
from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf
mnist = input_data.read_data_sets("MNIST_data/", one_hot = true)
sess = tf.InteractiveSession()
```

卷积神经网络中会有众多的权重和偏置需要创建，因此可以先定义好初始化函数，方便后续重复使用。此外我们还需给权重增加一些随机的噪声打破完全对称，比如可以使用截断的正太分布噪声，标准差设置为0.1。同时因为使用的激活函数式ReLU，也需要给偏置增加一些小的正值(0.1)来避免死亡节点(dead neurons)的出现。

```
def weight_variable(shape):
	initial = tf.truncated_normal(shape, stddev = 0.1)
	return tf.Variable(initial)

def bias_varibale(shape):
	initial = tf.constant(0.1, shape = shape)
	return tf.Varibale(initial)
```

卷积层和池化层在后续也可以重复利用，所以不妨对其分布定义创建函数。Tensorflow中的tf.nn.conv2d是标准2维卷积函数，参数中x是输入，W是卷积的参数，比如[5,5,1,32]：前两个数字代表卷积核的尺寸，第三个数字代表有多少个channel。如果是才是RGB图片，这里设置为3，本例由于是灰度单色，所以这里是1。最后一个数字代表卷积核的数量，是指这个卷积层会提取多少类特征。Strides代表卷积核移动的步长，全是1的话代表不遗漏的扫描图片的所有点。Padding是指处理边界的方式，这里使用SAME代表给边界上Padding让卷积的输入和输出保存一样的尺寸。tf.nn.max_pool是Tensorflow中的最大池化函数，这么使用的是2*2的最大池化函数，会保留原始像素块中灰度值最高的一个像素点。因为要整体上缩小图片尺寸，因此池化层的步长也设置为横竖两个方向为2的步长。

```
def con2d(x,W):
	return tf.nn.conv2d(x, W, strides = [1,1,1,1], padding = 'SAME')

def max_pool_2*2(x):
	return tf.nn.max_pool(x,ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')
```

接下来定义输入的placeholder，x是特征，y_是label。由于卷积神经网络会用到图片的空间信息，所以需要把一维的向量转变为二维的向量，MNIST数据集每张图片是784个像素点，可以转换为28*28的结构，同时由于图片是灰度单色，只有一个颜色通道，所以可以确定尺寸为[-1,28,28,-1]，-1是代表样本数据不确定的占位符，最后一个1是颜色通道量。向量变形的函数可以使用tf.reshape。

```
x = tf.placeholder(tf.float32, [None, 784])
y_ = tf.placeholder(tf.float32, [None, 10])
x_image = tf.reshape(x, [-1,28,28,1])
```

下面就可以定义第一个卷积层了。首先使用前面定义好的函数对weighs和bias进行参数初始化，这里的[5,5,1,32]代表卷积核卷积核尺寸为5*5，1个颜色通道，32个不同的卷积核。然后使用conv2d函数进行卷积操作，随后加上偏置，再使用ReLU激活函数进行非线性处理。最后使用最大池化函数对输出结果做池化操作。

```
W_conv1 = weight_variable([5,5,1,32])
b_conv1 = bias_variable([32])
h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool_2*2(h_conv1)
```

第二层卷积层基本结构跟第一个卷积层一样，唯一的变化是卷积核的数量为64，在这层卷积层中会提前64种特征。

```
W_conv2 = weight_variable([5,5,32,64])
b_conv2 = bias_variable([64])
h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool_2*2(h_conv2)
```

在经历过两层卷积层的提取特征后，尤其是经历2次步长为2*2的最大池化层后，现在的图片边长缩减为原来的1/4，变为了7*7。而第二个卷积层的卷积核数为64，所以第二层的输出数据的尺寸为7*7*64。我们继续使用tf.reshape函数对输出向量做变化，转为一维向量，再连接一个隐含节点数为1024的全连接层，使用ReLU激活函数。

```
W_fc1 = weight_variable([7*7*64, 1024])
b_fc1 = bias_variable([1024])
h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)
```

为了减轻过拟合，下面使用一个Dropout层，通过一个placeholder传入keep_prob比率来控制。在训练时，我们随机丢掉一部分节点数据来减轻过拟合，但是在预测时会保留所有数据从而追求更高的准确率。

```
keep_prob = tf.placeholder(tf.float32)
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)
```
最后将Dropout层连接一个Softmax函数，得到最后的概率。

```
W_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])
y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)
```

我们定义损失函数cross entropy，使用的优化器是Adam，学习速率为1e-4。

```
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
```

再定义评价准确率的操作。

```
correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_, 1))
accuracy = tf.reduce_mean(tf.cast(correct_predication, tf.float32))

```

下面是训练过程。首先会初始化所有参数，设置Dropout的keep_prob=0.5。然后使用大小为50的mini-batch，进行20000次的迭代训练。参与训练的样本数量总共为100万，其中每训练100次进行一次的性能测评(测评时keep_prob=1)，用来实时监测模型的性能。

```
tf.global_variables_initializer().run()
for i in range(20000):
	batch = mnist.train.next_batch(50)
	if i%100 == 0:
		train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob:1.0})
		print("step %d, training accuaracy %g" % (i, train_accuracy)
	train_step.run(feed_dict={x:batch[0], y_:batch[1], keep_prob:0.5})
```

训练完成后，在最终的测试集上进行全面测试，得到准确率。

```
print("test accuracy %g" % accuracy.eval(feed_dict={x:mnist.test.images, y_:mnist.test.labels, keep_prob:1.0}))
```

以上就是利用Tensorflow实现一个简单的卷积神经网络，在MNIST数据集上准确率大概为99.3%，基本满足对手写数字识别的准确率要求。性能的提升主要来自更优秀的网络设计，卷积网络对特性特征的提取和抽象能力。



### 7.3.7 卷积神经网络与迁移学习

7.3.5节中介绍了若干经典的卷积神经网络，这些网络结构已经在实际应用场景中发挥了重大作用，也取得了非常好的效果。那么如何使用上述网络结构呢？下面介绍迁移学习的相关内容。

迁移学习的目标是从关联任务中提取有效信息来辅助解决新的任务，根本出发点是目标领域的数据稀疏性。迁移学习的核心是利用已有的知识，去解决不同但是相关领域的问题，即以一个环境中学到的知识为基础解决另一个环境中的学习任务，迁移已有的知识解决目标领域中的学习问题，而目标领域只有少量、甚至没有样本数据。比如可以将已经训练好了的ALexNet、Google Net、VGGNet等网络中的某些层直接抽出来，化为己用。具体的来说，你可以将ALexNet中的最一层特征层抽出来，然后自己设计一个分类器或者直接用SVM分类器进行分类。当然你也可以抽取多个网络中的网络层，然后进行融合。总而言之，就是将已经学到了的“知识”化为己用。在最后，你要用自己的数据集进行一下微调（fine-tune）。


使用迁移学习主要有三种实现方式，其一是将预训练模型作为特征提取器来提取特征。把全连接层去掉，将剩下的网络当做一个固定的特征提取器，提取相关特征。其二是采用预训练模型的结构，根据自己的数据集去重新训练模型权重。其三是使用预训练模型的方法是对它微调(fine-tune)。冻结模型前期一些层的权重，重新训练后面的层，得到新的权重。

具体使用上述哪种方式，是由数据集大小和新旧数据集之间数据的相似度来决定的，可以分为四种情景。如果满足数据集小，数据相似度高的场景。因为数据与预训练模型的训练数据相似度很高，不需要重新训练模型，只需要将输出层改制成符合问题情境下的结构，使用预处理模型作为特征提取器即可。如果满足数据集小，数据相似度不高的场景。在这种情况下，可以冻结预训练模型中的前k个层中的权重，然后重新训练后面的n-k个层，采用fine-tune的训练方式。如果满足数据集大，数据相似度不高的场景。因为我们有一个很大的数据集，而且实际数据与预训练模型的训练数据之间存在很大差异。最好的方法还是将预处理模型中的权重全都初始化后在新数据集的基础上重头开始训练。最后一种场景，即满足数据集大，数据相似度高。这就是最理想的情况，采用预训练模型会变得非常高效。最好的运用方式是保持模型原有的结构和初始权重不变，直接训练即可。














